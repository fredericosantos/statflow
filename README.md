# Statflow - MLflow Experiment Analysis Tool

A comprehensive, modular Streamlit application for analyzing and visualizing MLflow experiment results with advanced parameter exploration, metrics comparison, and dataset analysis capabilities.

## Features

- **ðŸ  Home**: Overview and navigation to analysis pages
- **ðŸ”§ Parameters**: Explore and filter experiment parameters with correlation analysis
- **ðŸ“Š Metrics**: Analyze metrics distributions and experiment comparisons
- **ðŸ”¬ Single Dataset Analysis**: Deep dive into individual datasets with boxplots and Pareto fronts
- **ðŸ“‹ Multiple Datasets Comparison**: Compare configurations across datasets with statistical tests
- **ðŸ’¾ Export**: Bulk export tools for raw data, tables, and statistical analysis
- **âš™ï¸ Settings**: Customize colors, symbols, and graph settings (persisted to YAML)

## Quick Start

```bash
# Navigate to the project directory
cd /path/to/statflow

# Install dependencies
uv sync

# Run the multi-page application
uv run streamlit run src/statflow/Home.py
```

## Project Structure

```
statflow/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ statflow/            # Main package
â”‚       â”œâ”€â”€ __init__.py              # Package initialization
â”‚       â”œâ”€â”€ config.py                # Configuration management and YAML persistence
â”‚       â”œâ”€â”€ Home.py                  # Main entry point with navigation
â”‚       â”œâ”€â”€ pages/                   # Individual analysis pages
â”‚       â”‚   â”œâ”€â”€ 1_ðŸ”§_Parameters.py       # Parameter exploration and filtering
â”‚       â”‚   â”œâ”€â”€ 2_ðŸ“Š_Metrics.py          # Metrics analysis and comparison
â”‚       â”‚   â”œâ”€â”€ 3_ðŸ”¬_Single_Dataset.py   # Single dataset analysis
â”‚       â”‚   â”œâ”€â”€ 4_ðŸ“‹_Multiple_Datasets.py # Multiple datasets comparison
â”‚       â”‚   â”œâ”€â”€ 5_ðŸ’¾_Export.py           # Data export tools
â”‚       â”‚   â””â”€â”€ 6_âš™ï¸_Settings.py         # Settings and customization
â”‚       â”œâ”€â”€ pages_modules/           # Business logic modules
â”‚       â”‚   â”œâ”€â”€ module_1_Parameters/     # Parameter processing
â”‚       â”‚   â”œâ”€â”€ module_2_Metrics/        # Metrics processing
â”‚       â”‚   â”œâ”€â”€ module_3_Single_Dataset/ # Single dataset processing
â”‚       â”‚   â”œâ”€â”€ module_4_Multiple_Datasets/ # Multiple datasets processing
â”‚       â”‚   â”œâ”€â”€ module_5_Export/         # Export processing
â”‚       â”‚   â””â”€â”€ module_6_Settings/       # Settings processing
â”‚       â”œâ”€â”€ utils/                   # Utility modules
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ mlflow_client.py     # MLflow data fetching
â”‚       â”‚   â”œâ”€â”€ data_processing.py   # Data transformation and labeling
â”‚       â”‚   â”œâ”€â”€ table_builders/      # Table construction modules
â”‚       â”‚   â”œâ”€â”€ table_utils.py       # Shared table utilities
â”‚       â”‚   â”œâ”€â”€ visualization.py     # Colors and symbols
â”‚       â”‚   â”œâ”€â”€ styling.py           # Table styling and UI utilities
â”‚       â”‚   â””â”€â”€ export.py            # Export utilities
â”‚       â””â”€â”€ components/              # Reusable UI components
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ filters.py           # Filter widgets
â”‚           â”œâ”€â”€ graphs.py            # Graph rendering
â”‚           â”œâ”€â”€ tables.py            # Table display components
â”‚           â””â”€â”€ downloads.py         # Download buttons
â”œâ”€â”€ pyproject.toml          # Project configuration and dependencies
â”œâ”€â”€ plan_8.md              # Implementation plan 8
â”œâ”€â”€ plan_9.md              # Implementation plan 9
â”œâ”€â”€ plan_10.md             # Implementation plan 10
â”œâ”€â”€ plan_11.md             # Implementation plan 11
â”œâ”€â”€ plan_12.md             # Implementation plan 12
â””â”€â”€ README.md              # This file
```

## Configuration

User preferences (colors, symbols, graph settings) are automatically saved to `.statflow_config.yaml` in the project root.

### Default Settings

- **Colors**: Custom palette for different experiment variants
- **Symbols**: Distinct markers for different configurations
- **Graph Size**: 800x600 pixels
- **Display**: Median statistics, error bars enabled

## Data Sources

- **MLflow Tracking URI**: Configurable (default: http://0.0.0.0:5000)
- **Datasets**: Dynamic loading from MLflow experiments
- **Parameters**: Automatic parameter extraction and filtering
- **Metrics**: Comprehensive metrics analysis and comparison

## Export Formats

- **CSV**: Raw data and comparison tables
- **LaTeX**: Publication-ready tables with customizable formatting
- **Markdown**: Documentation-friendly tables
- **ZIP**: Bulk raw data archives

## Requirements

- Python 3.13+
- uv (for dependency management)
- Streamlit >=1.53.0
- MLflow >=3.8.1
- Polars >=1.37.1
- Plotly >=6.5.2
- NumPy, SciPy, Statsmodels

## Installation

```bash
# Clone the repository
git clone <repository-url>
cd statflow

# Install dependencies with uv
uv sync

# Run the application
uv run streamlit run src/statflow/Home.py
```

## Usage Notes

1. **Navigation**: Use the Home page to navigate between analysis modes
2. **Parameter Exploration**: Start with Parameters page to understand experiment configurations
3. **Metrics Analysis**: Use Metrics page to compare performance across experiments
4. **Dataset Analysis**: Dive deep into individual or multiple datasets
5. **Caching**: Data fetching is cached for performance - use refresh buttons if needed
6. **Filters**: Apply filters in sidebars to focus analysis on specific configurations
7. **Configuration**: Customize appearance in Settings - preferences persist between sessions
8. **Export**: Use the Export page for bulk downloads in multiple formats

## Development

The application follows a modular architecture with:
- Separation of concerns (data, visualization, UI)
- Reusable components
- Comprehensive caching for performance
- YAML-based configuration persistence
- Type hints and documentation throughout
- Polars DataFrames for efficient data processing
- Atomic file structure with single responsibilities

## Implementation Plans

The project was developed through iterative implementation plans:
- **plan_8.md**: Added Parameters and Metrics subpages
- **plan_9.md**: Fixed gaps and migrated to Polars
- **plan_10.md**: Completed remaining enhancements
- **plan_11.md**: Final integration and polish
- **plan_12.md**: Code quality improvements and future enhancements

## Contributing

1. Follow the established modular architecture
2. Use Polars for data processing
3. Add type hints and documentation
4. Follow DRY principles and atomic file structure
5. Test changes with real MLflow data