# Statflow - MLflow Experiment Analysis Tool

A comprehensive, modular Streamlit application for analyzing and visualizing MLflow experiment results with advanced parameter exploration, metrics comparison, and dataset analysis capabilities.

## Features

- **ðŸ  Home**: Overview and navigation to analysis pages
- **ðŸ”§ Parameters**: Explore and filter experiment parameters with correlation analysis
- **ðŸ“Š Metrics**: Analyze metrics distributions and experiment comparisons
- **ðŸ”¬ Single Dataset Analysis**: Deep dive into individual datasets with boxplots and Pareto fronts
- **ðŸ“‹ Multiple Datasets Comparison**: Compare configurations across datasets with statistical tests
- **ðŸ’¾ Export**: Bulk export tools for raw data, tables, and statistical analysis
- **âš™ï¸ Settings**: Customize colors, symbols, and graph settings (persisted to YAML)

## Quick Start

```bash
# Navigate to the project directory
cd /path/to/statflow

# Run the multi-page application
uv run streamlit run src/statflow/Home.py
```

## Project Structure

```
statflow/
â”œâ”€â”€ __init__.py              # Package initialization
â”œâ”€â”€ config.py                # Configuration management and YAML persistence
â”œâ”€â”€ Home.py                  # Main entry point with navigation
â”œâ”€â”€ pages/                   # Individual analysis pages
â”‚   â”œâ”€â”€ 1_ðŸ”§_Parameters.py       # Parameter exploration and filtering
â”‚   â”œâ”€â”€ 2_ðŸ“Š_Metrics.py          # Metrics analysis and comparison
â”‚   â”œâ”€â”€ 3_ðŸ”¬_Single_Dataset.py   # Single dataset analysis
â”‚   â”œâ”€â”€ 4_ðŸ“‹_Multiple_Datasets.py # Multiple datasets comparison
â”‚   â”œâ”€â”€ 5_ðŸ’¾_Export.py           # Data export tools
â”‚   â””â”€â”€ 6_âš™ï¸_Settings.py         # Settings and customization
â”œâ”€â”€ pages_modules/           # Business logic modules
â”‚   â”œâ”€â”€ module_1_Parameters/     # Parameter processing
â”‚   â”œâ”€â”€ module_2_Metrics/        # Metrics processing
â”‚   â”œâ”€â”€ module_3_Single_Dataset/ # Single dataset processing
â”‚   â”œâ”€â”€ module_4_Multiple_Datasets/ # Multiple datasets processing
â”‚   â”œâ”€â”€ module_5_Export/         # Export processing
â”‚   â””â”€â”€ module_6_Settings/       # Settings processing
â”œâ”€â”€ utils/                   # Utility modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ mlflow_client.py     # MLflow data fetching
â”‚   â”œâ”€â”€ data_processing.py   # Data transformation and labeling
â”‚   â”œâ”€â”€ table_builders/      # Table construction modules
â”‚   â”œâ”€â”€ table_utils.py       # Shared table utilities
â”‚   â”œâ”€â”€ visualization.py     # Colors and symbols
â”‚   â”œâ”€â”€ styling.py           # Table styling and UI utilities
â”‚   â””â”€â”€ export.py            # Export utilities
â””â”€â”€ components/              # Reusable UI components
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ filters.py           # Filter widgets
    â”œâ”€â”€ graphs.py            # Graph rendering
    â”œâ”€â”€ tables.py            # Table display components
    â””â”€â”€ downloads.py         # Download buttons
```

## Configuration

User preferences (colors, symbols, graph settings) are automatically saved to `.statflow_config.yaml`.

### Default Settings

- **Colors**: Custom palette for different experiment variants
- **Symbols**: Distinct markers for different configurations
- **Graph Size**: 800x600 pixels
- **Display**: Median statistics, error bars enabled

## Data Sources

- **MLflow Tracking URI**: Configurable (default: http://0.0.0.0:5000)
- **Datasets**: Dynamic loading from MLflow experiments
- **Parameters**: Automatic parameter extraction and filtering
- **Metrics**: Comprehensive metrics analysis and comparison

## Export Formats

- **CSV**: Raw data and comparison tables
- **LaTeX**: Publication-ready tables with customizable formatting
- **Markdown**: Documentation-friendly tables
- **ZIP**: Bulk raw data archives

## Requirements

- Python 3.13+
- Streamlit >=1.53.0
- MLflow >=3.8.1
- Polars >=1.37.1
- Plotly >=6.5.2
- NumPy, SciPy, Statsmodels

## Usage Notes

1. **Navigation**: Use the Home page to navigate between analysis modes
2. **Parameter Exploration**: Start with Parameters page to understand experiment configurations
3. **Metrics Analysis**: Use Metrics page to compare performance across experiments
4. **Dataset Analysis**: Dive deep into individual or multiple datasets
5. **Caching**: Data fetching is cached for performance - use refresh buttons if needed
6. **Filters**: Apply filters in sidebars to focus analysis on specific configurations
7. **Configuration**: Customize appearance in Settings - preferences persist between sessions
8. **Export**: Use the Export page for bulk downloads in multiple formats

## Development

The application follows a modular architecture with:
- Separation of concerns (data, visualization, UI)
- Reusable components
- Comprehensive caching for performance
- YAML-based configuration persistence
- Type hints and documentation throughout
- Polars DataFrames for efficient data processing